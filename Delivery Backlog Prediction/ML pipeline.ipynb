{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bdf721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "#from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "#from catboost import CatBoostRegressor\n",
    "#import category_encoders as ce\n",
    "random_state = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b0545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_after_outlier.csv', parse_dates=['ofd_date'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9b2bf2",
   "metadata": {},
   "source": [
    "- Add week & add boolean variable if it is a weekend \n",
    "- Encode categorical variables \n",
    "- Get the model cols \n",
    "- Filter by station \n",
    "    - Shift the data \n",
    "    - Split the data \n",
    "    - Scale the data \n",
    "    - Create lags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339e81ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weekend(df):\n",
    "    \"\"\" Adding whether it is a weekend or not as a column \"\"\" \n",
    "    \n",
    "    df['is_weekend'] = np.where(df['day_of_week'] < 5, 0, 1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def enhance_dates(df): \n",
    "    \"\"\" Adding a column that indicates the day of the week 0-Monday and 6-Sunday \"\"\"\n",
    "    \n",
    "    df['day_of_week'] = df.apply(lambda x: x['ofd_date'].weekday(), axis=1)\n",
    "    df.rename(columns = {'target':'Diff_val'}, inplace=True)\n",
    "    df = add_weekend(df)\n",
    "    return df\n",
    "\n",
    "def encode_categorical(df): \n",
    "    \"\"\" Carry out OneHot encoding on the categorical variables \"\"\"\n",
    "    \n",
    "    cols_to_encode = ['day_of_week', 'country_code']\n",
    "    df[cols_to_encode] = df[cols_to_encode].astype('str')\n",
    "    encoder=ce.OneHotEncoder(cols=cols_to_encode,handle_unknown='ignore',return_df=True,use_cat_names=True)\n",
    "    encoded_df = encoder.fit_transform(df)\n",
    "    return encoded_df\n",
    "\n",
    "\n",
    "def get_model_cols(df): \n",
    "    \"\"\" Function to get the list of model features \"\"\"\n",
    "    all_cols = df.columns.tolist()\n",
    "    drop_cols = ['index', 'ofd_date', 'fc_codes', 'Diff_val']\n",
    "    model_cols = list(set(all_cols) - set(drop_cols))\n",
    "    return model_cols\n",
    "    \n",
    "    \n",
    "def shift_data(df): \n",
    "    \"\"\" Shifting the data so that the target variable aligns with the features \"\"\"\n",
    "    target_column = df['Diff_val'][1:]\n",
    "    shifted_data = df.shift(1).dropna().drop(['Diff_val'], axis=1)\n",
    "    shifted_data['target'] = target_column\n",
    "    return shifted_data\n",
    "    \n",
    "def split_data(df): \n",
    "    \"\"\" Function to carry out train test split \"\"\"\n",
    "    df['Date'] = df['ofd_date'].apply(lambda x: x.strftime(\"%d-%m-%Y\"))\n",
    "    train_data = df[df['ofd_date'] < '2021-06-01'].set_index('ofd_date')\n",
    "    test_data = df[df['ofd_date'] >= '2021-06-01'].set_index('ofd_date')\n",
    "#     train_data.index.freq = 'd'\n",
    "#     test_data.index.freq = 'd'\n",
    "    return train_data, test_data\n",
    "\n",
    "def scale_data(train, test): \n",
    "    \"\"\" Function to scale the data using a Robust Scaler \"\"\"\n",
    "    scaler = RobustScaler()\n",
    "    scale_cols = ['OFD', 'Rollover', 'Returns', 'Slam', 'Earlies_Rec', 'R_Sideline', 'Sideline']\n",
    "    train[scale_cols] = scaler.fit_transform(train[scale_cols])\n",
    "    test[scale_cols] = scaler.transform(test[scale_cols])\n",
    "    return train, test\n",
    "    \n",
    "\n",
    "def preprocessing(df): \n",
    "    \"\"\" Function that preprocesses the data by enhancing the dates and encoding categorical variables\"\"\"\n",
    "    train = enhance_dates(df)\n",
    "    train = encode_categorical(train)\n",
    "    return train\n",
    "\n",
    "\n",
    "def ml_pipeline(df): \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Enter code to select the station here \n",
    "    #ONCE STATION IS SELECTED \n",
    "    \n",
    "    train = shift_data(df)\n",
    "    train, test = split_data(train)\n",
    "    model_columns = get_model_cols(train)\n",
    "    train, test = scale_data(train, test)\n",
    "    return train, test, model_columns\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_train= preprocessing(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb1d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_station = 'D76'\n",
    "selected_df = proc_train[proc_train['station_code'] == selected_station]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0177e31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test, model_cols = ml_pipeline(selected_df)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c96d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([train, test])\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33baffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=random_state),\n",
    "                lags = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e95fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.create_train_X_y(y=combined_df['target'], exog=combined_df[model_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ae8dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster.create_train_X_y(y=combined_df['target'], exog=combined_df[model_cols])[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1f34c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_series_data(data, time_lag): \n",
    "    proc_train  = preprocessing(data)\n",
    "    station_codes = proc_train['station_code'].unique().tolist()\n",
    "    for i in range(len(station_codes)): \n",
    "        print(f'Station code = {station_codes[i]}')\n",
    "        selected_df = proc_train[proc_train['station_code'] == station_codes[i]]\n",
    "        train, test, model_cols = ml_pipeline(selected_df)\n",
    "        combined_df = pd.concat([train, test])\n",
    "        forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=random_state),\n",
    "                lags = time_lag)\n",
    "        X_data = forecaster.create_train_X_y(y=combined_df['target'], exog=combined_df[model_cols])[0]\n",
    "        X_data['target'] = forecaster.create_train_X_y(y=combined_df['target'], exog=combined_df[model_cols])[1]\n",
    "        X_data['Index'] =  X_data['Date'] + '_' + X_data['station_code']\n",
    "        if i == 0: \n",
    "            transformed_data = X_data.copy()\n",
    "        else: \n",
    "            transformed_data = pd.concat([transformed_data, X_data])\n",
    "    \n",
    "    transformed_data = transformed_data.reset_index().drop('index', axis=1)\n",
    "    return transformed_data.sort_values(by='Index').set_index('Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = get_time_series_data(train, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15f08c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e853f95c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
